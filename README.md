Many thanks for taking the time to visit this repository.

Here you will find the source code used to train a deep learning classifier for hyper-acute detection of ECG changes caused by complete coronary artery occlusion. The preprint version of the paper can be found at https://arxiv.org/abs/1903.04421

TECHNICAL NOTES:
The libraries you will require to run the code (beyond those included as standard in Python 3.6) are listed in "python-dependencies.txt"

The code was originally executed on a machine with the following specifications:

-   Intel i9 2.9GHz processor
-   32GB RAM
-   NVIDIA GeForce GTX 1080 graphics card (CUDA-enabled)
-   460GB SSD hard drive

Without a CUDA-enabled system and TensorFlow set up to run on the GPU, the code may take a long time to execute. (On the system detailed above, the whole experiment can be exectued overnight.) Parts of the code required the full 32GB of RAM, so lower-spec systems may require workarounds.

EXECUTION NOTES:
Initially, a feasilibity experiment was run using limited data (see "first-training.py"). This produced encouraging results, so the system was fine-tuned on extended data (see "second-training.py"). For this reason, the training process is split into two parts and sets of training data are downloaded. This set-up could, of course, be streamlined. However, the intention was to reproduce the source code for the experiment exactly as it was run to produce the results in the paper.

To run the scripts in order: download this repository, navigate to it in a terminal window then copy and paste the following command:

python first-training.py && python second-training.py && python evaluate.py && python threshold-search.py && python evaluate-with-threshold.py && python analysis.py

By the time the data has been downloaded and the models created, approximated 13.5GB disk space will be required. The clinically-important metrics (sensitivity, specificity, F1, etc.) can be found in "Analsyis\_summary.txt". The confusion matrix and a full breakdown of predictions vs ground truth labels will also be generated, should users wish to calculate their own metrics.

We have not published the labels obtained from expert reviewers. However, human-readable versions of the ECGs used during this process can be generated by running "ecg\_plotter.py" should readers wish to repeat the classification task. All filenames of non-ischaemic ECGs end with the letter "a", so filenames will need to be changed to blind clinical reviewers to the true labels.

GENERAL NOTES:
Results rely on a 5-fold cross validation process, hence 5 different models being produced by each of the aforementioned scripts. It is important that no model is evaluated upon data from patients whose ECG signals it has already encountered, as it is apt to learn the idiosyncrasies of an indivual patient's ECG morphology and overperform. The resultant, artificially high results will not generalise to the wider population.

Please note that the these models are training using stochastic gradient descent (or variations thereupon). As a result, the same code can be run multiple times with varying results. It may be necessary to run through the training process multiple times in order to reproduce the results reported in the paper.

In our experience, optimal thresholds for F1 scoring can sometimes be at the extremes of the range (e.g. &lt; 0.05). These are not anomolous findings, but rather due to the fact that activation of the output node of the model is based on the sigmoid function and the loss function is based on a logarithmic scale, which encourages the model's predictions to be clustered at the extremes of the output range rather than being based on linear confidence estimation.

All code was written by Dr Rob Brisk (specialty doctor in cardiology, Craigavon Hospital / PhD student at the school of computer science, Ulster University). Correspondence to <robbrisk@hotmail.com>. All code and text is copyright Ulster University, 2019.
